{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vaegan_with_added_loss_term.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "i7Yf9JmJPldV",
        "colab_type": "code",
        "outputId": "9e4003fe-998d-4ece-f524-fabc51906636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 28kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x62106000 @  0x7f407a8622a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ow4bOJW7AihP",
        "colab_type": "code",
        "outputId": "1869cbaa-ae81-4166-b010-c3408feb1a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\r\u001b[K    18% |██████                          | 10kB 16.6MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 20kB 3.5MB/s eta 0:00:01\r\u001b[K    56% |██████████████████              | 30kB 5.0MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████        | 40kB 3.7MB/s eta 0:00:01\r\u001b[K    93% |██████████████████████████████  | 51kB 4.5MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 61kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EPr5SiU9PUFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy\n",
        "import argparse\n",
        "numpy.random.seed(8)\n",
        "torch.manual_seed(8)\n",
        "torch.cuda.manual_seed(8)\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "from torch.optim import RMSprop,Adam,SGD\n",
        "from torch.optim.lr_scheduler import ExponentialLR,MultiStepLR\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q3Dehf-zPUFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy\n",
        "import numpy as np\n",
        "import sys\n",
        "# encoder block (used in encoder and discriminator)\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        # convolution to halve the dimensions\n",
        "        self.conv = nn.Conv2d(in_channels=channel_in, out_channels=channel_out, kernel_size=5, padding=2, stride=2,\n",
        "                              bias=False)\n",
        "        self.bn = nn.BatchNorm2d(num_features=channel_out, momentum=0.9)\n",
        "\n",
        "    def forward(self, ten, out=False,t = False):\n",
        "        # here we want to be able to take an intermediate output for reconstruction error\n",
        "        if out:\n",
        "            ten = self.conv(ten)\n",
        "            ten_out = ten\n",
        "            ten = self.bn(ten)\n",
        "            ten = F.relu(ten, False)\n",
        "            return ten, ten_out\n",
        "        else:\n",
        "            ten = self.conv(ten)\n",
        "            ten = self.bn(ten)\n",
        "            ten = F.relu(ten, True)\n",
        "            return ten\n",
        "\n",
        "\n",
        "# decoder block (used in the decoder)\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        # transpose convolution to double the dimensions\n",
        "        self.conv = nn.ConvTranspose2d(channel_in, channel_out, kernel_size=5, padding=2, stride=2, output_padding=1,\n",
        "                                       bias=False)\n",
        "        self.bn = nn.BatchNorm2d(channel_out, momentum=0.9)\n",
        "\n",
        "    def forward(self, ten):\n",
        "        #print(\"Input size: \"),\n",
        "        #print(ten.shape)\n",
        "        #print(\"Decoder block size: \",)\n",
        "        ten = self.conv(ten)\n",
        "        #print(ten.size())\n",
        "        ten = self.bn(ten)\n",
        "        ten = F.relu(ten, True)\n",
        "        return ten\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, channel_in=3, z_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.size = channel_in\n",
        "        layers_list = []\n",
        "        # the first time 3->64, for every other double the channel size\n",
        "        for i in range(3):\n",
        "            if i == 0:\n",
        "                layers_list.append(EncoderBlock(channel_in=self.size, channel_out=64))\n",
        "                self.size = 64\n",
        "            else:\n",
        "                layers_list.append(EncoderBlock(channel_in=self.size, channel_out=self.size * 2))\n",
        "                self.size *= 2\n",
        "\n",
        "        # final shape Bx256x8x8\n",
        "        self.conv = nn.Sequential(*layers_list)\n",
        "        self.fc = nn.Sequential(nn.Linear(in_features=8 * 8 * self.size, out_features=1024, bias=False),\n",
        "                                nn.BatchNorm1d(num_features=1024,momentum=0.9),\n",
        "                                nn.ReLU(True))\n",
        "        # two linear to get the mu vector and the diagonal of the log_variance\n",
        "        self.l_mu = nn.Linear(in_features=1024, out_features=z_size)\n",
        "        self.l_var = nn.Linear(in_features=1024, out_features=z_size)\n",
        "\n",
        "    def forward(self, ten):\n",
        "        ten = self.conv(ten)\n",
        "        ten = ten.view(len(ten), -1)\n",
        "        ten = self.fc(ten)\n",
        "        mu = self.l_mu(ten)\n",
        "        logvar = self.l_var(ten)\n",
        "        return mu, logvar\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return super(Encoder, self).__call__(*args, **kwargs)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, z_size, size):\n",
        "        super(Decoder, self).__init__()\n",
        "        # start from B*z_size\n",
        "        self.fc = nn.Sequential(nn.Linear(in_features=z_size, out_features=8 * 8 * size, bias=False),\n",
        "                                nn.BatchNorm1d(num_features=8 * 8 * size,momentum=0.9),\n",
        "                                nn.ReLU(True))\n",
        "        self.size = size\n",
        "        layers_list = []\n",
        "        layers_list.append(DecoderBlock(channel_in=self.size, channel_out=self.size))\n",
        "        layers_list.append(DecoderBlock(channel_in=self.size, channel_out=self.size//2))\n",
        "        self.size = self.size//2\n",
        "        layers_list.append(DecoderBlock(channel_in=self.size, channel_out=self.size//4))\n",
        "        self.size = self.size//4\n",
        "        # final conv to get 3 channels and tanh layer\n",
        "        layers_list.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels=self.size, out_channels=3, kernel_size=5, stride=1, padding=2),\n",
        "            nn.Tanh()\n",
        "        ))\n",
        "\n",
        "        self.conv = nn.Sequential(*layers_list)\n",
        "\n",
        "    def forward(self, ten):\n",
        "\n",
        "        ten = self.fc(ten)\n",
        "        ten = ten.view(len(ten), -1, 8, 8)\n",
        "        ten = self.conv(ten)\n",
        "        return ten\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return super(Decoder, self).__call__(*args, **kwargs)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channel_in=3,recon_level=3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.size = channel_in\n",
        "        self.recon_levl = recon_level\n",
        "        # module list because we need need to extract an intermediate output\n",
        "        self.conv = nn.ModuleList()\n",
        "        self.conv.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        self.size = 32\n",
        "        self.conv.append(EncoderBlock(channel_in=self.size, channel_out=128))\n",
        "        self.size = 128\n",
        "        self.conv.append(EncoderBlock(channel_in=self.size, channel_out=256))\n",
        "        self.size = 256\n",
        "        self.conv.append(EncoderBlock(channel_in=self.size, channel_out=256))\n",
        "        # final fc to get the score (real or fake)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=8 * 8 * self.size, out_features=512, bias=False),\n",
        "            nn.BatchNorm1d(num_features=512,momentum=0.9),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features=512, out_features=1),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, ten,ten_original,ten_sampled):\n",
        "\n",
        "        ten = torch.cat((ten, ten_original,ten_sampled), 0)\n",
        "\n",
        "        for i, lay in enumerate(self.conv):\n",
        "            # we take the 9th layer as one of the outputs\n",
        "            if i == self.recon_levl:\n",
        "                ten, layer_ten = lay(ten, True)\n",
        "                # we need the layer representations just for the original and reconstructed,\n",
        "                # flatten, because it's a convolutional shape\n",
        "                layer_ten = layer_ten.view(len(layer_ten), -1)\n",
        "            else:\n",
        "                ten = lay(ten)\n",
        "\n",
        "        ten = ten.view(len(ten), -1)\n",
        "        ten = self.fc(ten)\n",
        "        return layer_ten,torch.sigmoid(ten)\n",
        "\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return super(Discriminator, self).__call__(*args, **kwargs)\n",
        "      \n",
        "      \n",
        "'''HELLO Added code start...'''\n",
        "fun = nn.Conv2d(in_channels=1 , out_channels=8, kernel_size=3)\n",
        "b = np.array([[[[1,0,0],[0,-1,0],[0,0,0]]],[[[0,1,0],[0,-1,0],[0,0,0]]],[[[0,0,1],[0,-1,0],[0,0,0]]],[[[0,0,0],[1,-1,0],[0,0,0]]],[[[0,0,0],[0,-1,1],[0,0,0]]],[[[0,0,0],[0,-1,0],[1,0,0]]],[[[0,0,0],[0,-1,0],[0,1,0]]],[[[0,0,0],[0,-1,0],[0,0,1]]]])\n",
        "c = torch.tensor(b, dtype= torch.float,requires_grad=False )\n",
        "fun.weight = torch.nn.Parameter(c)\n",
        "fun.weight.requires_grad = False\n",
        "fun.bias = torch.nn.Parameter(torch.zeros(8))\n",
        "fun.bias.requires_grad = False\n",
        "fun.cuda()\n",
        "'''HELLO added code end ...'''\n",
        "\n",
        "class VaeGan(nn.Module):\n",
        "    def __init__(self,z_size=128,recon_level=3):\n",
        "        super(VaeGan, self).__init__()\n",
        "        # latent space size\n",
        "        self.z_size = z_size\n",
        "        self.encoder = Encoder(z_size=self.z_size)\n",
        "        self.decoder = Decoder(z_size=self.z_size, size=self.encoder.size)\n",
        "        self.discriminator = Discriminator(channel_in=3,recon_level=recon_level)\n",
        "        # self-defined function to init the parameters\n",
        "        self.init_parameters()\n",
        "\n",
        "    def init_parameters(self):\n",
        "        # just explore the network, find every weight and bias matrix and fill it\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
        "                if hasattr(m, \"weight\") and m.weight is not None and m.weight.requires_grad:\n",
        "                    #init as original implementation\n",
        "                    scale = 1.0/numpy.sqrt(numpy.prod(m.weight.shape[1:]))\n",
        "                    scale /=numpy.sqrt(3)\n",
        "                    #nn.init.xavier_normal(m.weight,1)\n",
        "                    #nn.init.constant(m.weight,0.005)\n",
        "                    nn.init.uniform(m.weight,-scale,scale)\n",
        "                if hasattr(m, \"bias\") and m.bias is not None and m.bias.requires_grad:\n",
        "                    nn.init.constant(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, ten, gen_size=10):\n",
        "        if self.training:\n",
        "            # save the original images\n",
        "            ten_original = ten\n",
        "            # encode\n",
        "            mus, log_variances = self.encoder(ten)\n",
        "            # we need the true variances, not the log one\n",
        "            variances = torch.exp(log_variances * 0.5)\n",
        "            # sample from a gaussian\n",
        "\n",
        "            ten_from_normal = Variable(torch.randn(len(ten), self.z_size).cuda(), requires_grad=True)\n",
        "            # shift and scale using the means and variances\n",
        "\n",
        "            ten = ten_from_normal * variances + mus\n",
        "            # decode the tensor\n",
        "            ten = self.decoder(ten)\n",
        "            ten_from_normal = Variable(torch.randn(len(ten), self.z_size).cuda(), requires_grad=True)\n",
        "            ten_from_normal = self.decoder(ten_from_normal)\n",
        "            #discriminator\n",
        "            ten_layer,ten_class = self.discriminator(ten,ten_original,ten_from_normal)\n",
        "\n",
        "            return ten, ten_class, ten_layer, mus, log_variances\n",
        "\n",
        "        else:\n",
        "            if ten is None:\n",
        "                # just sample and decode\n",
        "\n",
        "                ten = Variable(torch.randn(gen_size, self.z_size).cuda(), requires_grad=False)\n",
        "                ten = self.decoder(ten)\n",
        "            else:\n",
        "                mus, log_variances = self.encoder(ten)\n",
        "                # we need the true variances, not the log one\n",
        "                variances = torch.exp(log_variances * 0.5)\n",
        "                # sample from a gaussian\n",
        "\n",
        "                ten_from_normal = Variable(torch.randn(len(ten), self.z_size).cuda(), requires_grad=False)\n",
        "                # shift and scale using the means and variances\n",
        "                ten = ten_from_normal * variances + mus\n",
        "                # decode the tensor\n",
        "                ten = self.decoder(ten)\n",
        "            return ten\n",
        "\n",
        "\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return super(VaeGan, self).__call__(*args, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def loss(ten_original, ten_predicted, layer_original, layer_predicted,layer_sampled, labels_original,\n",
        "             labels_predicted,labels_sampled, mus, variances):\n",
        "        \"\"\"\n",
        "\n",
        "        :param ten_original: original images\n",
        "        :param ten_predicted:  predicted images (output of the decoder)\n",
        "        :param layer_original:  intermediate layer for original (intermediate output of the discriminator)\n",
        "        :param layer_predicted: intermediate layer for reconstructed (intermediate output of the discriminator)\n",
        "        :param labels_original: labels for original (output of the discriminator)\n",
        "        :param labels_predicted: labels for reconstructed (output of the discriminator)\n",
        "        :param labels_sampled: labels for sampled from gaussian (0,1) (output of the discriminator)\n",
        "        :param mus: tensor of means\n",
        "        :param variances: tensor of diagonals of log_variances\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        # reconstruction error, not used for the loss but useful to evaluate quality\n",
        "        nle = 0.5*(ten_original.view(len(ten_original), -1) - ten_predicted.view(len(ten_predicted), -1)) ** 2\n",
        "        # kl-divergence\n",
        "        kl = -0.5 * torch.sum(-variances.exp() - torch.pow(mus,2) + variances + 1, 1)\n",
        "        # mse between intermediate layers for both\n",
        "        mse_1 = torch.sum(0.5*(layer_original - layer_predicted) ** 2, 1)\n",
        "        mse_2 = torch.sum(0.5*(layer_original - layer_sampled) ** 2, 1)\n",
        "        # bce for decoder and discriminator for original,sampled and reconstructed\n",
        "        # the only excluded is the bce_gen_original\n",
        "\n",
        "        bce_dis_original = -torch.log(labels_original + 1e-3)\n",
        "        bce_dis_sampled = -torch.log(1 - labels_sampled + 1e-3)\n",
        "        bce_dis_recon = -torch.log(1 - labels_predicted+ 1e-3)\n",
        "\n",
        "        #bce_gen_original = -torch.log(1-labels_original + 1e-3)\n",
        "        bce_gen_sampled = -torch.log(labels_sampled + 1e-3)\n",
        "        bce_gen_recon = -torch.log(labels_predicted+ 1e-3)\n",
        "        \n",
        "        \n",
        "        '''HELLO added code start...'''\n",
        "        ten_original = torch.mean(ten_original,1,True) # comment this if mnist is used\n",
        "        ten_predicted = torch.mean(ten_predicted,1,True) #comment this if mnist is used\n",
        "\n",
        "        original = fun(ten_original)\n",
        "        reconst = fun(ten_predicted)\n",
        "        \n",
        "        org , _ = torch.max(original,1)\n",
        "        rec , _ = torch.max(reconst,1)\n",
        "        \n",
        "        mse_3 = torch.sum(0.5*(org - rec) ** 2, 1)\n",
        "        \n",
        "        \n",
        "        '''HELLO added code end...'''    \n",
        "        \n",
        "        \n",
        "        '''\n",
        "        \n",
        "\n",
        "        bce_gen_predicted = nn.BCEWithLogitsLoss(size_average=False)(labels_predicted,\n",
        "                                         Variable(torch.ones_like(labels_predicted.data).cuda(), requires_grad=False))\n",
        "        bce_gen_sampled = nn.BCEWithLogitsLoss(size_average=False)(labels_sampled,\n",
        "                                       Variable(torch.ones_like(labels_sampled.data).cuda(), requires_grad=False))\n",
        "        bce_dis_original = nn.BCEWithLogitsLoss(size_average=False)(labels_original,\n",
        "                                        Variable(torch.ones_like(labels_original.data).cuda(), requires_grad=False))\n",
        "        bce_dis_predicted = nn.BCEWithLogitsLoss(size_average=False)(labels_predicted,\n",
        "                                         Variable(torch.zeros_like(labels_predicted.data).cuda(), requires_grad=False))\n",
        "        bce_dis_sampled = nn.BCEWithLogitsLoss(size_average=False)(labels_sampled,\n",
        "                                       Variable(torch.zeros_like(labels_sampled.data).cuda(), requires_grad=False))\n",
        "        '''\n",
        "        return nle, kl, mse_1,mse_2,\\\n",
        "               bce_dis_original, bce_dis_sampled,bce_dis_recon,bce_gen_sampled,bce_gen_recon,mse_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gf8WHPJ5PUF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# just a class to store a rolling average\n",
        "# useful to log to TB\n",
        "class RollingMeasure(object):\n",
        "    def __init__(self):\n",
        "        self.measure = 0.0\n",
        "        self.iter = 0\n",
        "    def __call__(self, measure):\n",
        "        # passo nuovo valore e ottengo average\n",
        "        # se first call inizializzo\n",
        "        if self.iter == 0:\n",
        "            self.measure = measure\n",
        "        else:\n",
        "            self.measure = (1.0 / self.iter * measure) + (1 - 1.0 / self.iter) * self.measure\n",
        "        self.iter += 1\n",
        "        return self.measure"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4kbeKw7PUF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MNIST(Dataset):\n",
        "    def __init__(self,X,Y):\n",
        "        self.X=X\n",
        "        self.Y=Y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self,index):\n",
        "        return self.X[index],self.Y[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LB8t98-fFuKW",
        "colab_type": "code",
        "outputId": "cef77b9b-398e-4079-f53e-b992b6fbd0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/d2/e08fe62f3554fbba081e80f6b23128df53b2f74ed4dcde73ec4a84dc53fb/tensorboardX-1.4-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K    15% |████▉                           | 10kB 24.1MB/s eta 0:00:01\r\u001b[K    30% |█████████▊                      | 20kB 4.6MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 30kB 6.4MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▌            | 40kB 4.3MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▍       | 51kB 5.3MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▎  | 61kB 6.2MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.14.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (40.6.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yn6yIaXOMVeA",
        "colab_type": "code",
        "outputId": "a04d530a-f846-4d7c-dfeb-c8e81c2d48e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Collecting image\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ec/51969468a8b87f631cc0e60a6bf1e5f6eec8ef3fd2ee45dc760d5a93b82a/image-1.5.27-py2.py3-none-any.whl\n",
            "Collecting django (from image)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/9a/0c028ea0fe4f5803dda1a7afabeed958d0c8b79b0fe762ffbf728db3b90d/Django-2.1.4-py3-none-any.whl (7.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 7.3MB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Installing collected packages: django, image\n",
            "Successfully installed django-2.1.4 image-1.5.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KJjKaaOtDNyN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "data = zipfile.ZipFile('mnist_png.zip', 'r')\n",
        "data.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XJ31ZsKuPUGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "from skimage import filters,transform\n",
        "\n",
        "train_x_data=[]\n",
        "train_y_data=[]\n",
        "\n",
        "count=0\n",
        "\n",
        "for number in range(10):\n",
        "    file_directory=\"mnist_png/mnist_png/training/\"+str(number)+\"/\"\n",
        "    count=0\n",
        "    for each_file in os.listdir(file_directory):\n",
        "        if(count>500):\n",
        "          break\n",
        "        count+=1\n",
        "        image=cv2.imread(file_directory+str(each_file))\n",
        "        image=numpy.float64(image)\n",
        "        image = cv2.resize(image, (64,64))\n",
        "        h=image.shape[0]\n",
        "        w=image.shape[1]\n",
        "        for i in range(h):\n",
        "          for j in range(w):\n",
        "            image[i][j]=image[i][j]/255.0\n",
        "        #image = numpy.stack((image,)*3, axis=-1)\n",
        "        train_x_data.append(image)\n",
        "        train_y_data.append(number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sGcMKgWRe84g",
        "colab_type": "code",
        "outputId": "6b8208b9-5aba-4d71-e059-5c78fdc42a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(train_x_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3bOt6ikvRvro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset=MNIST(train_x_data, train_y_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbZ3QzTCqP6V",
        "colab_type": "code",
        "outputId": "e53d4430-0835-4271-afc5-d1d21030574a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "z_size=128\n",
        "recon_level=3\n",
        "net = VaeGan(z_size=z_size,recon_level=recon_level).cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:200: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:202: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rGmZDUqEPUGL",
        "colab_type": "code",
        "outputId": "584f4965-7572-4095-83de-f102f616784e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2414
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tensorboardX\n",
        "from tensorboardX import SummaryWriter\n",
        "import cv2\n",
        "from skimage import filters,transform\n",
        "#import progressbar\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "writer=SummaryWriter()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    dataset = MNIST(train_x_data, train_y_data)\n",
        "\n",
        "    z_size = 128\n",
        "    recon_level = 3\n",
        "    decay_mse = 1.0\n",
        "    decay_margin = 1.0\n",
        "    n_epochs = 7\n",
        "    lambda_mse = 1e-6\n",
        "    lr = 0.001\n",
        "    decay_lr = 0.75\n",
        "    decay_equilibrium = 1.0\n",
        "    \n",
        "    # DATASET\n",
        "    \n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    dataloader_test = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "    \n",
        "    #margin and equilibirum\n",
        "    margin = 0.35\n",
        "    equilibrium = 0.68\n",
        "    mse_lambda = 1.0\n",
        "    # OPTIM-LOSS\n",
        "    # an optimizer for each of the sub-networks, so we can selectively backprop\n",
        "    optimizer_encoder = RMSprop(params=net.encoder.parameters(),lr=lr,alpha=0.9,eps=1e-8,weight_decay=0,momentum=0,centered=False)\n",
        "    #lr_encoder = MultiStepLR(optimizer_encoder,milestones=[2],gamma=1)\n",
        "    lr_encoder = ExponentialLR(optimizer_encoder, gamma=decay_lr)\n",
        "    optimizer_decoder = RMSprop(params=net.decoder.parameters(),lr=lr,alpha=0.9,eps=1e-8,weight_decay=0,momentum=0,centered=False)\n",
        "    lr_decoder = ExponentialLR(optimizer_decoder, gamma=decay_lr)\n",
        "    #lr_decoder = MultiStepLR(optimizer_decoder,milestones=[2],gamma=1)\n",
        "    optimizer_discriminator = RMSprop(params=net.discriminator.parameters(),lr=lr,alpha=0.9,eps=1e-8,weight_decay=0,momentum=0,centered=False)\n",
        "    lr_discriminator = ExponentialLR(optimizer_discriminator, gamma=decay_lr)\n",
        "    #lr_discriminator = MultiStepLR(optimizer_discriminator,milestones=[2],gamma=1)\n",
        "\n",
        "    batch_number = len(dataloader)\n",
        "    step_index = 0\n",
        "    for i in range(n_epochs):\n",
        "        #progress = progressbar.ProgressBar(min_value=0, max_value=batch_number, initial_value=0, widgets=widgets).start()\n",
        "        # reset rolling average\n",
        "        print(\"Epoch number: \",i)\n",
        "        loss_nle_mean = RollingMeasure()\n",
        "        loss_encoder_mean = RollingMeasure()\n",
        "        loss_decoder_mean = RollingMeasure()\n",
        "        loss_discriminator_mean = RollingMeasure()\n",
        "        loss_reconstruction_layer_mean = RollingMeasure()\n",
        "        loss_kld_mean = RollingMeasure()\n",
        "        gan_gen_eq_mean = RollingMeasure()\n",
        "        gan_dis_eq_mean = RollingMeasure()\n",
        "        #print(\"LR:{}\".format(lr_encoder.get_lr()))\n",
        "\n",
        "        # for each batch\n",
        "        count=0\n",
        "        for j, (data_batch,target_batch) in enumerate(dataloader):\n",
        "            # set to train mode\n",
        "            count+=len(data_batch)\n",
        "            if(count%3000==0):\n",
        "              print(\"count: \",count)\n",
        "            train_batch = len(data_batch)\n",
        "            data_batch=data_batch.transpose(2,3).transpose(1,2)\n",
        "            net.train()\n",
        "            # target and input are the same images\n",
        "            data_target = Variable(data_batch, requires_grad=False).float().cuda()\n",
        "            data_in = Variable(data_batch, requires_grad=False).float().cuda()\n",
        "\n",
        "            # get output\n",
        "            out, out_labels, out_layer, mus, variances = net(data_in)\n",
        "            \n",
        "            # split so we can get the different parts\n",
        "            out_layer_predicted = out_layer[:train_batch]\n",
        "            out_layer_original = out_layer[train_batch:-train_batch]\n",
        "            out_layer_sampled = out_layer[-train_batch:]\n",
        "            #labels\n",
        "            out_labels_predicted = out_labels[:train_batch]\n",
        "            out_labels_original = out_labels[train_batch:-train_batch]\n",
        "            out_labels_sampled = out_labels[-train_batch:]\n",
        "            # loss, nothing special here\n",
        "            nle_value, kl_value, mse_value_1,mse_value_2, bce_dis_original_value, bce_dis_sampled_value, \\\n",
        "            bce_dis_predicted_value,bce_gen_sampled_value,bce_gen_predicted_value, mse_value_3= VaeGan.loss(data_target, out, out_layer_original,\n",
        "                                                                         out_layer_predicted,out_layer_sampled, out_labels_original,\n",
        "                                                                          out_labels_predicted,out_labels_sampled, mus,\n",
        "                                                                         variances)\n",
        "            # THIS IS THE MOST IMPORTANT PART OF THE CODE\n",
        "            loss_encoder = torch.sum(kl_value)+torch.sum(mse_value_1)+torch.sum(mse_value_2)+torch.sum(mse_value_3)\n",
        "            loss_discriminator = torch.sum(bce_dis_original_value) + torch.sum(bce_dis_sampled_value)+ torch.sum(bce_dis_predicted_value)\n",
        "            loss_decoder = torch.sum(bce_gen_sampled_value) + torch.sum(bce_gen_predicted_value)\n",
        "            loss_decoder =torch.sum(lambda_mse/2 * mse_value_3)+ torch.sum(lambda_mse/2 * mse_value_1)+ torch.sum(lambda_mse/2 * mse_value_2) + (1.0 - lambda_mse) * loss_decoder\n",
        "\n",
        "            # register mean values of the losses for logging\n",
        "            loss_nle_mean(torch.mean(nle_value).data.cpu().numpy())\n",
        "            loss_discriminator_mean((torch.mean(bce_dis_original_value) + torch.mean(bce_dis_sampled_value)).data.cpu().numpy())\n",
        "            loss_decoder_mean((torch.mean(lambda_mse * mse_value_3/2)+torch.mean(lambda_mse * mse_value_1/2)+torch.mean(lambda_mse * mse_value_2/2) + (1 - lambda_mse) * (torch.mean(bce_gen_predicted_value) + torch.mean(bce_gen_sampled_value))).data.cpu().numpy())\n",
        "\n",
        "            loss_encoder_mean((torch.mean(kl_value) + torch.mean(mse_value_1)+torch.mean(mse_value_3)+ torch.mean(mse_value_2)).data.cpu().numpy())\n",
        "            loss_reconstruction_layer_mean((torch.mean(mse_value_1)+torch.mean(mse_value_3)+torch.mean(mse_value_2)).data.cpu().numpy())\n",
        "            loss_kld_mean(torch.mean(kl_value).data.cpu().numpy())\n",
        "            # selectively disable the decoder of the discriminator if they are unbalanced\n",
        "            train_dis = True\n",
        "            train_dec = True\n",
        "            if torch.mean(bce_dis_original_value).data.cpu().numpy() < equilibrium-margin or torch.mean(bce_dis_sampled_value).data.cpu().numpy() < equilibrium-margin:\n",
        "                train_dis = False\n",
        "            if torch.mean(bce_dis_original_value).data.cpu().numpy() > equilibrium+margin or torch.mean(bce_dis_sampled_value).data.cpu().numpy() > equilibrium+margin:\n",
        "                train_dec = False\n",
        "            if train_dec is False and train_dis is False:\n",
        "                train_dis = True\n",
        "                train_dec = True\n",
        "\n",
        "            #aggiungo log\n",
        "            if train_dis:\n",
        "                gan_dis_eq_mean(1.0)\n",
        "            else:\n",
        "                gan_dis_eq_mean(0.0)\n",
        "\n",
        "            if train_dec:\n",
        "                gan_gen_eq_mean(1.0)\n",
        "            else:\n",
        "                gan_gen_eq_mean(0.0)\n",
        "\n",
        "            # BACKPROP\n",
        "            # clean grads\n",
        "            net.zero_grad()\n",
        "            # encoder\n",
        "            loss_encoder.backward(retain_graph=True)\n",
        "            # someone likes to clamp the grad here\n",
        "            #[p.grad.data.clamp_(-1,1) for p in net.encoder.parameters()]\n",
        "            # update parameters\n",
        "            optimizer_encoder.step()\n",
        "            # clean others, so they are not afflicted by encoder loss\n",
        "            net.zero_grad()\n",
        "            #decoder\n",
        "            if train_dec:\n",
        "                loss_decoder.backward(retain_graph=True)\n",
        "                #[p.grad.data.clamp_(-1,1) for p in net.decoder.parameters()]\n",
        "                optimizer_decoder.step()\n",
        "                #clean the discriminator\n",
        "                net.discriminator.zero_grad()\n",
        "            #discriminator\n",
        "            if train_dis:\n",
        "                loss_discriminator.backward()\n",
        "                #[p.grad.data.clamp_(-1,1) for p in net.discriminator.parameters()]\n",
        "                optimizer_discriminator.step()\n",
        "        \n",
        "        lr_encoder.step()\n",
        "        lr_decoder.step()\n",
        "        lr_discriminator.step()\n",
        "        margin *=decay_margin\n",
        "        equilibrium *=decay_equilibrium\n",
        "        #margin non puo essere piu alto di equilibrium\n",
        "        if margin > equilibrium:\n",
        "            equilibrium = margin\n",
        "        lambda_mse *=decay_mse\n",
        "        if lambda_mse > 1:\n",
        "            lambda_mse=1\n",
        "        #progress.finish()\n",
        "        \n",
        "        writer.add_scalar('loss_encoder', loss_encoder_mean.measure, step_index)\n",
        "        writer.add_scalar('loss_decoder', loss_decoder_mean.measure, step_index)\n",
        "        writer.add_scalar('loss_discriminator', loss_discriminator_mean.measure, step_index)\n",
        "        writer.add_scalar('loss_reconstruction', loss_nle_mean.measure, step_index)\n",
        "        writer.add_scalar('loss_kld',loss_kld_mean.measure,step_index)\n",
        "        writer.add_scalar('gan_gen',gan_gen_eq_mean.measure,step_index)\n",
        "        writer.add_scalar('gan_dis',gan_dis_eq_mean.measure,step_index)\n",
        "        \n",
        "        testloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, num_workers=4)\n",
        "    \n",
        "        for j, (data_batch,target_batch) in enumerate(testloader):\n",
        "          if(j>1):\n",
        "            break\n",
        "          train_batch = len(data_batch)\n",
        "          data_batch=data_batch.transpose(2,3).transpose(1,2)\n",
        "          data_target = Variable(target_batch, requires_grad=False).float().cuda()\n",
        "          data_in = Variable(data_batch, requires_grad=False).float().cuda()\n",
        "          out, out_labels, out_layer, mus, variances = net(data_in)\n",
        "          \n",
        "        input_images=data_in.data.cpu().numpy()\n",
        "        output_images=out.data.cpu().numpy()\n",
        "        print(input_images[0][0])\n",
        "        print(output_images[0][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number:  0\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[-0.00048327 -0.00060821 -0.00073909 ... -0.00089363 -0.00070014\n",
            "  -0.00064636]\n",
            " [-0.00032886 -0.00040314 -0.00056372 ... -0.00061949 -0.00051634\n",
            "  -0.00054266]\n",
            " [-0.00044484 -0.00071135 -0.00075847 ... -0.00098871 -0.00069427\n",
            "  -0.00063263]\n",
            " ...\n",
            " [-0.00038112 -0.00049403 -0.00064508 ... -0.00059458 -0.00061288\n",
            "  -0.00052513]\n",
            " [-0.00022525 -0.0004436  -0.00032047 ... -0.00045386 -0.00025826\n",
            "  -0.00026477]\n",
            " [-0.0001873  -0.00020897 -0.00030366 ... -0.00020861 -0.00028496\n",
            "  -0.00021828]]\n",
            "Epoch number:  1\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[-0.00041741  0.00106655  0.00054518 ...  0.00289834  0.00209633\n",
            "   0.00390781]\n",
            " [ 0.00129754  0.00326908  0.00247221 ...  0.0029752   0.0045426\n",
            "   0.00588443]\n",
            " [ 0.00225413  0.00381138  0.00252945 ...  0.003183    0.00378743\n",
            "   0.00573912]\n",
            " ...\n",
            " [ 0.0034836   0.00554109  0.00461572 ...  0.00408004  0.00474518\n",
            "   0.00612843]\n",
            " [ 0.00509073  0.00843378  0.00827087 ...  0.00693916  0.0081934\n",
            "   0.00878194]\n",
            " [ 0.00582122  0.00966356  0.0071022  ...  0.00679583  0.00860624\n",
            "   0.00894472]]\n",
            "Epoch number:  2\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0.00015024 0.00015026 0.00013738 ... 0.00015026 0.00015027 0.00015027]\n",
            " [0.00015021 0.00015024 0.00015935 ... 0.00015027 0.00015026 0.00015028]\n",
            " [0.00015022 0.00015028 0.00014263 ... 0.00015027 0.00015027 0.00015027]\n",
            " ...\n",
            " [0.00015018 0.00015017 0.00015018 ... 0.00015026 0.00015026 0.00015026]\n",
            " [0.00015014 0.00015016 0.00015019 ... 0.00015026 0.00015026 0.00015026]\n",
            " [0.0001502  0.00015021 0.00015024 ... 0.00015026 0.00015026 0.00015026]]\n",
            "Epoch number:  3\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[-2.2378829e-04  1.0394756e-04  1.7037257e-04 ...  3.8048216e-05\n",
            "  -2.1412285e-04  1.3047564e-04]\n",
            " [ 4.5604157e-04  9.5839612e-04  3.9550549e-04 ...  9.1814218e-05\n",
            "  -2.4904648e-04 -1.9946754e-04]\n",
            " [ 5.7935878e-04  1.2775999e-03  3.3815295e-04 ...  7.3319662e-04\n",
            "  -2.1210353e-06 -3.4189237e-05]\n",
            " ...\n",
            " [ 1.4002991e-04  3.7595892e-04  1.8307650e-04 ... -1.1702412e-03\n",
            "   3.6702745e-04  2.1430106e-04]\n",
            " [ 2.3551905e-04  3.8674904e-04 -1.3304752e-04 ... -2.0015586e-04\n",
            "   3.9031761e-04  3.7022750e-05]\n",
            " [-3.6910380e-05  1.2165556e-04  1.6737878e-05 ... -4.7837774e-04\n",
            "  -2.9918263e-04  7.7172866e-05]]\n",
            "Epoch number:  4\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[ 1.6482896e-03  3.1829823e-03  2.4379713e-03 ...  2.5869098e-03\n",
            "   1.6818520e-03  3.3245205e-03]\n",
            " [ 1.8666808e-03  2.7433613e-03  2.0180757e-03 ...  2.2469200e-04\n",
            "   8.2026527e-06  2.0810722e-03]\n",
            " [ 6.4818864e-04  2.0391788e-04  1.2433175e-04 ...  4.9329636e-04\n",
            "  -8.3800539e-04  1.9696224e-03]\n",
            " ...\n",
            " [ 1.5231845e-04 -2.1360037e-04 -1.5242628e-04 ... -1.9992276e-03\n",
            "  -2.1086091e-03 -9.4669225e-04]\n",
            " [ 5.7507091e-04  1.4897304e-03  1.1058387e-03 ...  2.9063807e-04\n",
            "   1.3172025e-03  5.8830366e-03]\n",
            " [-4.7628081e-04  1.0340485e-04 -1.9957926e-04 ... -1.4670547e-03\n",
            "   1.5878627e-03  7.8230090e-03]]\n",
            "Epoch number:  5\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[ 3.63258645e-04  5.64393413e-04  2.93492398e-04 ...  3.04396381e-04\n",
            "   1.81165378e-04  8.62442539e-05]\n",
            " [ 3.10050789e-04  5.75299666e-04  2.23484851e-04 ...  1.75469904e-04\n",
            "   6.62288512e-05 -2.97711958e-05]\n",
            " [ 9.72375492e-05  5.83642141e-05  1.05649662e-04 ...  4.70900268e-04\n",
            "   4.21017117e-04  2.44847994e-04]\n",
            " ...\n",
            " [ 1.53155110e-04 -5.09421807e-05 -1.55032001e-04 ... -1.82861200e-04\n",
            "  -2.26497825e-04  1.04606588e-05]\n",
            " [ 2.88360170e-04  2.85687187e-04  3.16126359e-04 ...  5.84159279e-04\n",
            "   4.78259870e-04  2.87394330e-04]\n",
            " [-6.30542345e-05 -1.83629192e-04 -1.18069525e-04 ... -1.94546650e-04\n",
            "  -1.38431526e-04  1.81318232e-04]]\n",
            "Epoch number:  6\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[ 3.37343983e-04  7.63769087e-04  1.19942706e-04 ... -2.88441981e-04\n",
            "  -9.92216592e-05 -3.79130943e-05]\n",
            " [ 1.49605505e-04  4.14493901e-04 -1.57257775e-04 ... -1.88343474e-04\n",
            "  -1.26008817e-04 -1.26729807e-04]\n",
            " [-2.60794710e-04 -5.71441953e-04 -4.78439615e-04 ... -8.86646885e-05\n",
            "  -1.23381964e-04 -2.54554878e-04]\n",
            " ...\n",
            " [-2.34148116e-04 -2.36324733e-04 -2.93455756e-04 ... -4.64618148e-04\n",
            "  -5.28910896e-04 -7.95696571e-04]\n",
            " [-2.03182819e-04 -1.76639820e-04 -1.39678101e-04 ... -3.19826824e-04\n",
            "  -2.28346209e-04  1.55322871e-03]\n",
            " [-2.24611125e-04 -3.40549683e-04 -2.53964972e-04 ... -5.46236115e-04\n",
            "   3.17771715e-04  3.47800204e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKLMOT1baLKG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zpIkFQH4SFbe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_input=[]\n",
        "x_input = train_x_data[300:300+100]\n",
        "x_input = torch.Tensor(x_input).cuda()\n",
        "x_input = x_input.transpose(2,3).transpose(1,2)\n",
        "out, out_labels, out_layer, mus, variances = net(x_input)\n",
        "\n",
        "input_images = x_input.data.cpu().numpy()\n",
        "output_images = out.data.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mk1LHRx_X9EP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(input_images[0][0])):\n",
        "  for j in range(len(input_images[0][0][0])):\n",
        "    input_images[0][0][i][j]=1-input_images[0][0][i][j]\n",
        "    output_images[0][0][i][j]=1-output_images[0][0][i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uFz8T0NKalwR",
        "colab_type": "code",
        "outputId": "f59f2a81-2339-4418-82df-107d392bf8f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#plt.imshow(input_images[0][0])\n",
        "print(output_images[0][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.89501244e-04  2.89706426e-04  2.89678574e-04 ...  2.13949344e-04\n",
            "   2.35039275e-04  3.43089865e-04]\n",
            " [ 2.89564457e-04  2.84708862e-04  2.71538680e-04 ...  1.53376546e-04\n",
            "   1.07258966e-04  3.39066959e-04]\n",
            " [ 2.89733085e-04  2.90170952e-04  2.72956531e-04 ...  2.33672414e-04\n",
            "   2.27823301e-04  3.90221103e-04]\n",
            " ...\n",
            " [ 2.59018445e-04  1.97219269e-04  2.62208981e-04 ...  3.89610068e-05\n",
            "  -5.47120289e-05  1.43168465e-04]\n",
            " [ 2.79990549e-04  2.26387303e-04  3.81324644e-04 ...  1.80962699e-04\n",
            "   3.09649273e-04  1.10583263e-03]\n",
            " [ 2.59507244e-04  1.71280859e-04  2.93184567e-04 ...  3.96237592e-05\n",
            "   3.54024436e-04  1.13481982e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V6UqLjK5SWE8",
        "colab_type": "code",
        "outputId": "834e4d22-9d0d-4936-8502-5dee76d063ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#plt.imshow(input_images[1][0])\n",
        "print(output_images[1][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.8955698e-04  2.8958026e-04  2.8957578e-04 ...  2.3538424e-04\n",
            "   2.7143481e-04  3.3369832e-04]\n",
            " [ 2.8953038e-04  2.8955602e-04  2.8956830e-04 ...  2.2702699e-04\n",
            "   2.0773057e-04  3.3281327e-04]\n",
            " [ 2.8954717e-04  2.8953271e-04  2.8956213e-04 ...  2.9502096e-04\n",
            "   2.5814687e-04  3.4626416e-04]\n",
            " ...\n",
            " [ 2.8956539e-04  2.8609092e-04  2.7285688e-04 ...  3.9899489e-05\n",
            "  -1.8724299e-05  8.4478001e-05]\n",
            " [ 2.8956617e-04  2.5275990e-04  3.1325466e-04 ...  1.3760984e-04\n",
            "   3.2395334e-04  1.0727930e-03]\n",
            " [ 2.8957188e-04  2.5171341e-04  3.0140809e-04 ...  1.4443067e-05\n",
            "   2.7785337e-04  1.1596754e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sR8yLmz8SXwJ",
        "colab_type": "code",
        "outputId": "cf894915-801c-4e8b-c709-50e4192b7cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,1)\n",
        "# Hide grid lines\n",
        "ax.grid(False)\n",
        "\n",
        "# Hide axes ticks\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.imshow(output_images[35][1], cmap='gray')\n",
        "#fig.savefig('6_with_loss.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faff9457828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEvRJREFUeJztncmvFdUWhzcqdlcBQUD6IEKCTeLA\nEKOJY8f+p06NAyfGaDAiKIRGUQFBFGyxb97Iyrd/79Z+Vx7COvd+32gf9j5Vdeq6rN+q1ex1f/31\nVxORetx1py9ARJZH4xQpisYpUhSNU6QoGqdIUe4ZTS4tLU2vctetW9fN+ZZX5NZw48aNdcv9u09O\nkaJonCJFGcpaoowVub345BQpisYpUhSNU6QoGqdIUTROkaJonCJF0ThFiqJxihRF4xQpisYpUhSN\nU6QoGqdIUTROkaJonCJF0ThFiqJxihRF4xQpisYpUhSNU6QoGqdIUTROkaJonCJF0ThFirLivrWy\nduDWG7kNx113zf//nGvZ53j0neyHzM9//vnnsuPRuVYTPjlFiqJxihRF4xQpij7nGoK+X/qB9OHu\nvvvuafzQQw916/j5gQce6Obuu+++ZdctLS116+g//vzzz93c119/PY2vX78+jb/77rtu3Y8//jiN\n/4nPuUi+qk9OkaJonCJFUdYuIPfcc8/w8988/PDD3WfK1dEx7r///mn84IMPduu2bNkyjTdt2tTN\nUSrv2bNnGj/yyCOz5/r888+7uW+++WYanz9/fhp/+eWX3brLly9P4wz3UCqndP3tt9+mcYZnSAXJ\n65NTpCgap0hRlLVFybeplIIbN27s5rZu3TqNKScfe+yxbh1lLt+sttba+vXrp/EPP/wwu47SON/W\n/vrrr9N4+/bt0zhlLSUjz9taa5s3b57GlM2Usa21tnv37mWPl9dImdxaa5cuXVp2Lt8a//HHH7PH\nv1345BQpisYpUhSNU6Qo+pz/AqNKjvThCEMY9957bze3YcOGaZwhDPpf9DMPHTrUraM/x++01vuj\nzOih//a/oJ/G742Okb4e/dYbN25MY2YLtdba1atXp3GGWX755ZdpfOXKlW6O9/Gjjz6axl999VW3\njhlI/F2t3T4f1CenSFE0TpGiKGtvEaMQA0MJGQbZu3fvst9LKUj5l7KZMpQhDMrY1lo7fPjwNE5p\nTLlH2ZYSjpIxr+Onn35adh3HSc4xa4fZPOkO7NixYxpnJhQl6ug+8np5rtZa+/3335dddzvxySlS\nFI1TpCgap0hR1ozPudIi2/RRRiEBVmzQX0xfb9u2bdP4wIEDs3McZyiFPmJWisz5X/QjW+tTADNt\njveEoQMWP7fW+3MMZ7TWhyaYbpcpdLxX6bey6oW+OlMUc45+dmt9OOn777/v5uZ88qxQYQpjhnsM\npYiscTROkaKsalmbkulvsuKDr+lTMlI+ZXUFZRGze1JO8jOla2u9BKM8ZYglj5+hA8pV/paR/EoZ\nx88MHaQkZaYOKzxa6zN62PMnM2y++OKLaZw9ipghxOtIebpr165pnLKW9yfvFUNZPHfK/FEh9u3C\nJ6dIUTROkaKsalk7l3CeUurRRx+dxildKTuzeHnuzWK+raXsohxrrX8LO8oQokRn9kprvXz99ttv\npzGTt1tr7bPPPpvG+Rb2zJkzyx4/E8KZ0cM3mq31MpT3O6+Dx8+kdX6P0pKyvrX+7W0m8fMep1yl\nPKZkzywgZgxZbC0iHRqnSFE0TpGirGqfk34bfbt9+/Z16/bv3z+NMxNlzq9srfdV6ffwO/k5M3/o\nE82Fflob+z30l+gHpr948eLFaZzbG9AHpV/J77TW+7TXrl3r5uhb0t8fFVRnyIL3h3+/rEqhX5+F\n2PRj03env3vhwoVpnD54hn/uBD45RYqicYoUZVXJ2pSFlEKUtZl8/txzz03jfC0/2pqAMpdhkAzV\njK6RMovSldk2rfUy9OzZs90cE9CZfTNK5k7ZRinLEANlbGu9FMzEd8payskM/VDy5jXOFRrkvac0\nTtlMOT/aEZtSNn/n3N/lduKTU6QoGqdIUTROkaKsKp8zq03oL+7cuXMaP/PMM926I0eOTOMMgzDU\nka/zWQ3CcfoovK70v+g7MTTx6aefdutYvJxzTDVjn9Y8F8Mi6afRXxxVpay0cdfIZxuFKfg9ruN9\n+l/XOKrM4d+J9yAbfFmVIiKzaJwiRVl4WctX41mBQFnLjBJuk5dz+cqejOTYqOcMd29OqXnu3Llp\nzOLlzMyh3E4JRjnMY2QxNEMMWVFC6c3febNZS7eC0fFH8pq/LeVpuj5z53JnaxGZReMUKYrGKVKU\nhfc5CV+Tt9Y3d2LKXnYj4LqsuKePmK/zmVLHUMeJEye6dewykD4Q0+F4vPSjPv7442mc/iK/x0r/\n9H3zM5nzMyv4Xssxuq5/0tjsb0a+9Z3CJ6dIUTROkaIsvKzlq/EsZGYxNMMnWTRNOZyhDsrEt956\nq5ujJH333Xence6mzIqVDNVQvjLUkVkv/JzXuNJmVBWlWxUqynefnCJF0ThFirLwspZSLd+0zu1E\nlTtPk5SMp0+fnsavv/56N/fee+9NYxYe5/GZiJ3HZ8L56E0r36bebDbLrV4n/y4+OUWKonGKFEXj\nFCnKwvucbAKVjbW4t8lKq01y74633357GmcohaEPhjOynyvnsrKFYRxmrxj2EJ+cIkXROEWKsvCy\nlq/9M/F9aWlpGjO5PQtumaWT/XmOHTs2jTO8wdDHSvuc5vYAXKuUFeKTU6QoGqdIUTROkaIsvM+5\n0n036NuNqjrYjKu1fu+R3CaO5zMMIrcan5wiRdE4RYqy8LKWcjVlLeUrpWaGUniMub6mrf13qCbD\nInPXYZWH3Aw+OUWKonGKFGXhZS0lZLauvH79+jRmknomwVPK5k5io4R59iziuVe6BUBr8xlCFXa5\nkjuLT06RomicIkXROEWKsvA+J8MluU0Bt0hgEXVuAcjqlaeeeqqbe/nll6dx9rvlFns8fm69N8pi\nInOhn8TQzNrAJ6dIUTROkaIsvKwluTMXwyeUnbkzNPvdbtu2rZt76aWXpjHlbx7z+PHj0zgziUY7\nLfOa2cM2r3GlYZaKkjcl+s1c4604xqLhk1OkKBqnSFE0TpGiLLzPSd8j0/e4bR79z/TZmIaX2wjy\nc+6BwmZgbCDGrQfzujId8MaNG9OYIZhTp05167h79WgflTvJ3I7Yo3TGle77kv++FgrafXKKFEXj\nFCnKwstakvKOIQz2AmK/2STl0vr166dxbvewb9++aczwyebNm7t1DMGk5CWffPLJNH711Ve7uaNH\nj85+j7I5QzBkpeEHys4MC1Hm55aLvHfZp4nwnia8/rlxa/3feiTrFznk4pNTpCgap0hRVrWs/emn\nn6Yx39ayCLu1XoJlsfVo52yej3KVb25b6+Xwxo0buzn2IeKuaCkLeR1nz57t5ihrv/3222nMt9Wt\njSUvj883yhs2bOjW8Ro5bq2Xq7yP6SrwfuQc7ymv/8qVK906fubftrX+757/TSySzPXJKVIUjVOk\nKBqnSFFWlc+ZzPkv6YuNMnhupug5/51+Zfa6ZdYRfdoXXnihW8csmwxvMEzEY2RGE0NIWcFDH3Hr\n1q3T+MCBA926Q4cOTeO9e/d2cwwZ0a/M653LJGqt94u5/cX58+e7dSdPnlz2eK21dvXq1WnMSp/l\nzlcZn5wiRdE4RYqyqmRtShaGIyjjmETe2n8nzBNKppRnPB+T0fN4nMssI8LjZ8jl6aefnsYp1T74\n4INpzN+WmVCU+XkMSuDdu3dP4+eff75bd/DgwWmc2U7MHhqFUihdGfZorb93vMZNmza1OdJNyd3g\nFhWfnCJF0ThFiqJxihRlVfmcCcMP9MWyryzTvzL1jqGPTH+jH0u/J4uh6UumP8pr5LkyjZB+YBaE\nsykZC8DZgKy13gcfhXR4rv3793fr6Gdm2Im/k+NROGpUbcKw0JYtW7p1vMbt27d3c7wHi1yU7ZNT\npCgap0hR1oysZeH1559/3q3j5507d3ZzDH2knGRGTEqruXUpBVnJMScL83Nm/lBqPvnkk9N4VK2R\nYSdeF8MWGcLIc5O5HcLzXPy7ZH8hylDe7wxBcWuMDDvxe7n9YpV+SyvBJ6dIUTROkaKsalk7l8HD\nt3mttfbhhx9OY74FbK3vE5RvOCk1KV1HrTf/SRL43LrswUPJx7e8KQVHmVBzBeej682CcEpGrhtl\nCKXs5Lk5l8fgG2om6rfWF4izKGDR8MkpUhSNU6QoGqdIUdaMz8kKh4sXL3br3nzzzWlMH7O1ceOu\nlZw3P6efNtffNf1bHmPUS/Zm+8oy24lhp8x24uec49YSvI70kXnu9Dl5j3kPRvdtFB4xQ0hEbjka\np0hRVrWsJZQ+WYR8+fLlaXz69Olujj1zVio1R9sNjLaMoLTMgmFKyFEoZS7jqLVeQuZ1MEmehQEp\nXfmbsw8RQyRMVM9QB8MlzPRprc9U4m/Je88tL7J/Lo+hrBWRW47GKVIUjVOkKGvG5xyFM1iITf+z\ntdYuXLgwjXPfEIYqRg2tRrtv02/juT/66KNuHfu2ZviB18EqkqyA4XXQ122tDy9xnH7lqCCc10Ff\nPX1f+qP5W/iZaZDp+/JeffbZZ90c3ylkKuUi4ZNTpCgap0hR1oysJRlGoOxilktr/VZz2U+HIYw5\nOdZaL5tz+8EzZ85M4+PHjy87zmNkr1eGHEZZTJTUo36x3EYw7xWPv2PHjm6O2VQMn2QYhO5BVs7M\nVenk32W0pSMlsLJWRG45GqdIUdakrE2pQ/mUrRops7J/zlyvmnyzyDej77//fjf32muvTWNuq3Dt\n2rVu3ahAmZ/nxq31b6nzHsy1AE1Jyt+c94MF5yyGzt3ImNGT2U68ZhYrZD8kFlGnrJ0r+l40fHKK\nFEXjFCmKxilSlDXpcyZzvVJb67dZyKwaZuPQz8kwxblz56bxqVOnurljx45N48wKIiNfcq6Z1sjf\nWumO3elXZrYPmet9m1spZBE4YUiH9/7s2bPdOn7OJl4Mu8wVsy8CPjlFiqJxihRlTcraUY+fUaJ3\nSt65njy5azSzjLKYmxKYBcSZETOSoSlz/yZ/56hH7txWCvmbR4n1nGMvplzH4+f95tYYJ0+enMbp\nDnBdhll470a9gKvjk1OkKBqnSFE0TpGirEmfc7R3R75659yoPypDDFkZwnQ1pri11ocLmFKXhcz0\nfTPljb+H1zhqSJb3gJ/pI2aB+RNPPDGNud1ga629+OKLy67L38J7zGqb1lo7evToNKbP+fHHH3fr\nGD7hPWytD8foc4rILUfjFCnKmpS1o52W89X+aNs8HodSM0MHjz/++DTes2dPN8eCZcqz0Y7SWaDM\nOWbfZKYS5WTeA87xGCnRuUXi008/3c2x+oRSNq+DoQ9W4rTWh5rYyyizgFiJkpVEiyxliU9OkaJo\nnCJFWZOyNqGkS1nLZPd8Y0jYPyezalh4/Morr3RzlLwnTpyYxvkWk9I138JSAo+Kw5m5lNKYv5tz\nuZUCrzeLqPlml1k6mcHzzjvvTOO8p2xFyvaXzAhqrXcBFjm5fYRPTpGiaJwiRdE4RYqyJn3OfNXO\nV/Hpc7KHK6tLWut9M4ZPMiNm48aN0zizahhaOXLkyOy56INm6IDhHp47i5pHIRJ+ZrYTr721PsMp\nM5XoZzJEkkXkzPxJf5S/m9sS8u/Q2jgstFrwySlSFI1TpCjrRpJgaWlpVeqFTPqm3Nu1a1c3d/Dg\nwdk5FkcfPnx4Gj/77LPdulGYhVCqZVYN5XZKb7LS/rYpV+d2vU4JzXW5Qzh78r7xxhvTOCXp1atX\np3Hu4M1MIIZ+RuGSRZe1N27cWLaS3ienSFE0TpGiaJwiRTGU0sbFv/SB0lel77d9+/ZpnM25mAKX\n4Ye5PrCZXsfKmVFzLpJ+GtP+MgWQv42/K3v18nPuKM3tDBkGyWLoS5cuTeP0R+eacy26X3kz+OQU\nKYrGKVKUNSlrE4YOUmZRTuXWfgwJcMu+Tz/9tFvHcAyrOlqbD7OM+hzldVDycpzH4Fz2MuIxGd6g\nPG2tL3LOzB/+bt6bzALi51FYaK3jk1OkKBqnSFE0TpGi6HO23hfLhl4MA2RKHcMdDDFkShp9rJE/\nyk4CGUphWCT75zL8w+vP35LXT/g76XfTl85zjfxRpt5laClTAslaDJnM4ZNTpCgap0hRlLXBqBA7\n5SSl5qgahE2rUuIxW4ayNiUpM4tW2nc3K2BGlR2U4iOJTumamT+UzbxXK81okh6fnCJF0ThFirIm\ni61vFczAoZTNfrHs65NSc9Tzh8wlyOcxKXFTXo/67lBuM1soM3g4l5lKPCavQ8ZYbC2yYGicIkXR\nOEWKos/5f0Cfc6XhgawU4fdYAJ1hG/qP6c/NXcfoXKM5nsswyL+PPqfIgqFxihTFDKH/g5uReKPv\npJQlo9DE3DFH5xrNGQapgU9OkaJonCJF0ThFiqJxihRF4xQpisYpUhSNU6QoGqdIUTROkaJonCJF\n0ThFiqJxihRF4xQpisYpUhSNU6QoGqdIUSy2FrkDZA+n5fDJKVIUjVOkKBqnSFE0TpGiaJwiRdE4\nRYoy3I5BRO4cPjlFiqJxihRF4xQpisYpUhSNU6QoGqdIUf4DP+WAsw/McDAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7faff94ee400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZrYAUpgrxvEV",
        "colab_type": "code",
        "outputId": "3b9c71f9-4ffb-4c73-cc3a-a67447b5ef5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(input_images[30][1], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7faffd058630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7faffd0fba90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}